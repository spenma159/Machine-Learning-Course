{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Week 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ],
      "metadata": {
        "id": "SQFvdwtRuWoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cJFew26cuUaJ",
        "outputId": "ff39155c-c84f-4ae1-aada-eb394fba53ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet-cu101==1.7.0\n",
            "  Downloading mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0 MB)\n",
            "\u001b[K     |███████████████████████████████▌| 834.1 MB 1.1 MB/s eta 0:00:11tcmalloc: large alloc 1147494400 bytes == 0x562a4b026000 @  0x7fc61b185615 0x562a1173e4cc 0x562a1181e47a 0x562a117412ed 0x562a11832e1d 0x562a117b4e99 0x562a117af9ee 0x562a11742bda 0x562a117b4d00 0x562a117af9ee 0x562a11742bda 0x562a117b1737 0x562a11833c66 0x562a117b0daf 0x562a11833c66 0x562a117b0daf 0x562a11833c66 0x562a117b0daf 0x562a11743039 0x562a11786409 0x562a11741c52 0x562a117b4c25 0x562a117af9ee 0x562a11742bda 0x562a117b1737 0x562a117af9ee 0x562a11742bda 0x562a117b0915 0x562a11742afa 0x562a117b0c0d 0x562a117af9ee\n",
            "\u001b[K     |████████████████████████████████| 846.0 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2021.10.8)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.7.0\n",
            "Collecting d2l==0.17.2\n",
            "  Downloading d2l-0.17.2-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 513 kB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (1.0.0)\n",
            "Collecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 123.6 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (7.6.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (1.3.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l==0.17.2) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l==0.17.2) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.3.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.18.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l==0.17.2) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l==0.17.2) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l==0.17.2) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l==0.17.2) (2.0.0)\n",
            "Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed d2l-0.17.2 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U mxnet-cu101==1.7.0\n",
        "!pip install d2l==0.17.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional Neural Networks (AlexNet)\n",
        ":label:`sec_alexnet`\n",
        "\n",
        "\n",
        "Although CNNs were well known\n",
        "in the computer vision and machine learning communities\n",
        "following the introduction of LeNet,\n",
        "they did not immediately dominate the field.\n",
        "Although LeNet achieved good results on early small datasets,\n",
        "the performance and feasibility of training CNNs\n",
        "on larger, more realistic datasets had yet to be established.\n",
        "In fact, for much of the intervening time between the early 1990s\n",
        "and the watershed results of 2012,\n",
        "neural networks were often surpassed by other machine learning methods,\n",
        "such as support vector machines.\n",
        "\n",
        "\n",
        "For computer vision, this comparison is perhaps not fair.\n",
        "That is although the inputs to convolutional networks\n",
        "consist of raw or lightly-processed (e.g., by centering) pixel values, practitioners would never feed raw pixels into traditional models.\n",
        "Instead, typical computer vision pipelines\n",
        "consisted of manually engineering feature extraction pipelines.\n",
        "Rather than *learn the features*, the features were *crafted*.\n",
        "Most of the progress came from having more clever ideas for features,\n",
        "and the learning algorithm was often relegated to an afterthought.\n",
        "\n",
        "Although some neural network accelerators were available in the 1990s,\n",
        "they were not yet sufficiently powerful to make\n",
        "deep multichannel, multilayer CNNs\n",
        "with a large number of parameters.\n",
        "Moreover, datasets were still relatively small.\n",
        "Added to these obstacles, key tricks for training neural networks\n",
        "including parameter initialization heuristics,\n",
        "clever variants of stochastic gradient descent,\n",
        "non-squashing activation functions,\n",
        "and effective regularization techniques were still missing.\n",
        "\n",
        "Thus, rather than training *end-to-end* (pixel to classification) systems,\n",
        "classical pipelines looked more like this:\n",
        "\n",
        "1. Obtain an interesting dataset. In early days, these datasets required expensive sensors (at the time, 1 megapixel images were state-of-the-art).\n",
        "2. Preprocess the dataset with hand-crafted features based on some knowledge of optics, geometry, other analytic tools, and occasionally on the serendipitous discoveries of lucky graduate students.\n",
        "3. Feed the data through a standard set of feature extractors such as the SIFT (scale-invariant feature transform) :cite:`Lowe.2004`, the SURF (speeded up robust features) :cite:`Bay.Tuytelaars.Van-Gool.2006`, or any number of other hand-tuned pipelines.\n",
        "4. Dump the resulting representations into your favorite classifier, likely a linear model or kernel method, to train a classifier.\n",
        "\n",
        "If you spoke to machine learning researchers,\n",
        "they believed that machine learning was both important and beautiful.\n",
        "Elegant theories proved the properties of various classifiers.\n",
        "The field of machine learning was thriving, rigorous, and eminently useful. However, if you spoke to a computer vision researcher,\n",
        "you would hear a very different story.\n",
        "The dirty truth of image recognition, they would tell you,\n",
        "is that features, not learning algorithms, drove progress.\n",
        "Computer vision researchers justifiably believed\n",
        "that a slightly bigger or cleaner dataset\n",
        "or a slightly improved feature-extraction pipeline\n",
        "mattered far more to the final accuracy than any learning algorithm.\n",
        "\n",
        "## Learning Representations\n",
        "\n",
        "Another way to cast the state of affairs is that\n",
        "the most important part of the pipeline was the representation.\n",
        "And up until 2012 the representation was calculated mechanically.\n",
        "In fact, engineering a new set of feature functions, improving results, and writing up the method was a prominent genre of paper.\n",
        "SIFT :cite:`Lowe.2004`,\n",
        "SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`,\n",
        "HOG (histograms of oriented gradient) :cite:`Dalal.Triggs.2005`,\n",
        "[bags of visual words](https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision)\n",
        "and similar feature extractors ruled the roost.\n",
        "\n",
        "Another group of researchers,\n",
        "including Yann LeCun, Geoff Hinton, Yoshua Bengio,\n",
        "Andrew Ng, Shun-ichi Amari, and Juergen Schmidhuber,\n",
        "had different plans.\n",
        "They believed that features themselves ought to be learned.\n",
        "Moreover, they believed that to be reasonably complex,\n",
        "the features ought to be hierarchically composed\n",
        "with multiple jointly learned layers, each with learnable parameters.\n",
        "In the case of an image, the lowest layers might come\n",
        "to detect edges, colors, and textures.\n",
        "Indeed,\n",
        "Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton\n",
        "proposed a new variant of a CNN,\n",
        "*AlexNet*,\n",
        "that achieved excellent performance in the 2012 ImageNet challenge.\n",
        "AlexNet was named after Alex Krizhevsky,\n",
        "the first author of the breakthrough ImageNet classification paper :cite:`Krizhevsky.Sutskever.Hinton.2012`.\n",
        "\n",
        "Interestingly in the lowest layers of the network,\n",
        "the model learned feature extractors that resembled some traditional filters.\n",
        ":numref:`fig_filters` is reproduced from the AlexNet paper :cite:`Krizhevsky.Sutskever.Hinton.2012`\n",
        "and describes lower-level image descriptors.\n",
        "\n",
        "![Image filters learned by the first layer of AlexNet.](../img/filters.png)\n",
        ":width:`400px`\n",
        ":label:`fig_filters`\n",
        "\n",
        "Higher layers in the network might build upon these representations\n",
        "to represent larger structures, like eyes, noses, blades of grass, and so on.\n",
        "Even higher layers might represent whole objects\n",
        "like people, airplanes, dogs, or frisbees.\n",
        "Ultimately, the final hidden state learns a compact representation\n",
        "of the image that summarizes its contents\n",
        "such that data belonging to different categories can be easily separated.\n",
        "\n",
        "While the ultimate breakthrough for many-layered CNNs\n",
        "came in 2012, a core group of researchers had dedicated themselves\n",
        "to this idea, attempting to learn hierarchical representations of visual data\n",
        "for many years.\n",
        "The ultimate breakthrough in 2012 can be attributed to two key factors.\n",
        "\n",
        "### Missing Ingredient: Data\n",
        "\n",
        "Deep models with many layers require large amounts of data\n",
        "in order to enter the regime\n",
        "where they significantly outperform traditional methods\n",
        "based on convex optimizations (e.g., linear and kernel methods).\n",
        "However, given the limited storage capacity of computers,\n",
        "the relative expense of sensors,\n",
        "and the comparatively tighter research budgets in the 1990s,\n",
        "most research relied on tiny datasets.\n",
        "Numerous papers addressed the UCI collection of datasets,\n",
        "many of which contained only hundreds or (a few) thousands of images\n",
        "captured in unnatural settings with low resolution.\n",
        "\n",
        "In 2009, the ImageNet dataset was released,\n",
        "challenging researchers to learn models from 1 million examples,\n",
        "1000 each from 1000 distinct categories of objects.\n",
        "The researchers, led by Fei-Fei Li, who introduced this dataset\n",
        "leveraged Google Image Search to prefilter large candidate sets\n",
        "for each category and employed\n",
        "the Amazon Mechanical Turk crowdsourcing pipeline\n",
        "to confirm for each image whether it belonged to the associated category.\n",
        "This scale was unprecedented.\n",
        "The associated competition, dubbed the ImageNet Challenge\n",
        "pushed computer vision and machine learning research forward,\n",
        "challenging researchers to identify which models performed best\n",
        "at a greater scale than academics had previously considered.\n",
        "\n",
        "### Missing Ingredient: Hardware\n",
        "\n",
        "Deep learning models are voracious consumers of compute cycles.\n",
        "Training can take hundreds of epochs, and each iteration\n",
        "requires passing data through many layers of computationally-expensive\n",
        "linear algebra operations.\n",
        "This is one of the main reasons why in the 1990s and early 2000s,\n",
        "simple algorithms based on the more-efficiently optimized\n",
        "convex objectives were preferred.\n",
        "\n",
        "*Graphical processing units* (GPUs) proved to be a game changer\n",
        "in making deep learning feasible.\n",
        "These chips had long been developed for accelerating\n",
        "graphics processing to benefit computer games.\n",
        "In particular, they were optimized for high throughput $4 \\times 4$ matrix-vector products, which are needed for many computer graphics tasks.\n",
        "Fortunately, this math is strikingly similar\n",
        "to that required to calculate convolutional layers.\n",
        "Around that time, NVIDIA and ATI had begun optimizing GPUs\n",
        "for general computing operations,\n",
        "going as far as to market them as *general-purpose GPUs* (GPGPU).\n",
        "\n",
        "To provide some intuition, consider the cores of a modern microprocessor\n",
        "(CPU).\n",
        "Each of the cores is fairly powerful running at a high clock frequency\n",
        "and sporting large caches (up to several megabytes of L3).\n",
        "Each core is well-suited to executing a wide range of instructions,\n",
        "with branch predictors, a deep pipeline, and other bells and whistles\n",
        "that enable it to run a large variety of programs.\n",
        "This apparent strength, however, is also its Achilles heel:\n",
        "general-purpose cores are very expensive to build.\n",
        "They require lots of chip area,\n",
        "a sophisticated support structure\n",
        "(memory interfaces, caching logic between cores,\n",
        "high-speed interconnects, and so on),\n",
        "and they are comparatively bad at any single task.\n",
        "Modern laptops have up to 4 cores,\n",
        "and even high-end servers rarely exceed 64 cores,\n",
        "simply because it is not cost effective.\n",
        "\n",
        "By comparison, GPUs consist of $100 \\sim 1000$ small processing elements\n",
        "(the details differ somewhat between NVIDIA, ATI, ARM and other chip vendors),\n",
        "often grouped into larger groups (NVIDIA calls them warps).\n",
        "While each core is relatively weak,\n",
        "sometimes even running at sub-1GHz clock frequency,\n",
        "it is the total number of such cores that makes GPUs orders of magnitude faster than CPUs.\n",
        "For instance, NVIDIA's recent Volta generation offers up to 120 TFlops per chip for specialized instructions\n",
        "(and up to 24 TFlops for more general-purpose ones),\n",
        "while floating point performance of CPUs has not exceeded 1 TFlop to date.\n",
        "The reason for why this is possible is actually quite simple:\n",
        "first, power consumption tends to grow *quadratically* with clock frequency.\n",
        "Hence, for the power budget of a CPU core that runs 4 times faster (a typical number),\n",
        "you can use 16 GPU cores at $1/4$ the speed,\n",
        "which yields $16 \\times 1/4 = 4$ times the performance.\n",
        "Furthermore, GPU cores are much simpler\n",
        "(in fact, for a long time they were not even *able*\n",
        "to execute general-purpose code),\n",
        "which makes them more energy efficient.\n",
        "Last, many operations in deep learning require high memory bandwidth.\n",
        "Again, GPUs shine here with buses that are at least 10 times as wide as many CPUs.\n",
        "\n",
        "Back to 2012. A major breakthrough came\n",
        "when Alex Krizhevsky and Ilya Sutskever\n",
        "implemented a deep CNN\n",
        "that could run on GPU hardware.\n",
        "They realized that the computational bottlenecks in CNNs,\n",
        "convolutions and matrix multiplications,\n",
        "are all operations that could be parallelized in hardware.\n",
        "Using two NVIDIA GTX 580s with 3GB of memory,\n",
        "they implemented fast convolutions.\n",
        "The code [cuda-convnet](https://code.google.com/archive/p/cuda-convnet/)\n",
        "was good enough that for several years\n",
        "it was the industry standard and powered\n",
        "the first couple years of the deep learning boom.\n",
        "\n",
        "## AlexNet\n",
        "\n",
        "AlexNet, which employed an 8-layer CNN,\n",
        "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
        "by a phenomenally large margin.\n",
        "This network showed, for the first time,\n",
        "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision.\n",
        "\n",
        "The architectures of AlexNet and LeNet are very similar,\n",
        "as :numref:`fig_alexnet` illustrates.\n",
        "Note that we provide a slightly streamlined version of AlexNet\n",
        "removing some of the design quirks that were needed in 2012\n",
        "to make the model fit on two small GPUs.\n",
        "\n",
        "![From LeNet (left) to AlexNet (right).](http://d2l.ai/_images/alexnet.svg)\n",
        ":label:`fig_alexnet`\n",
        "\n",
        "The design philosophies of AlexNet and LeNet are very similar,\n",
        "but there are also significant differences.\n",
        "First, AlexNet is much deeper than the comparatively small LeNet5.\n",
        "AlexNet consists of eight layers: five convolutional layers,\n",
        "two fully-connected hidden layers, and one fully-connected output layer. Second, AlexNet used the ReLU instead of the sigmoid\n",
        "as its activation function.\n",
        "Let us delve into the details below.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "In AlexNet's first layer, the convolution window shape is $11\\times11$.\n",
        "Since most images in ImageNet are more than ten times higher and wider\n",
        "than the MNIST images,\n",
        "objects in ImageNet data tend to occupy more pixels.\n",
        "Consequently, a larger convolution window is needed to capture the object.\n",
        "The convolution window shape in the second layer\n",
        "is reduced to $5\\times5$, followed by $3\\times3$.\n",
        "In addition, after the first, second, and fifth convolutional layers,\n",
        "the network adds maximum pooling layers\n",
        "with a window shape of $3\\times3$ and a stride of 2.\n",
        "Moreover, AlexNet has ten times more convolution channels than LeNet.\n",
        "\n",
        "After the last convolutional layer there are two fully-connected layers\n",
        "with 4096 outputs.\n",
        "These two huge fully-connected layers produce model parameters of nearly 1 GB.\n",
        "Due to the limited memory in early GPUs,\n",
        "the original AlexNet used a dual data stream design,\n",
        "so that each of their two GPUs could be responsible\n",
        "for storing and computing only its half of the model.\n",
        "Fortunately, GPU memory is comparatively abundant now,\n",
        "so we rarely need to break up models across GPUs these days\n",
        "(our version of the AlexNet model deviates\n",
        "from the original paper in this aspect).\n",
        "\n",
        "### Activation Functions\n",
        "\n",
        "Besides, AlexNet changed the sigmoid activation function to a simpler ReLU activation function. On one hand, the computation of the ReLU activation function is simpler. For example, it does not have the exponentiation operation found in the sigmoid activation function.\n",
        " On the other hand, the ReLU activation function makes model training easier when using different parameter initialization methods. This is because, when the output of the sigmoid activation function is very close to 0 or 1, the gradient of these regions is almost 0, so that backpropagation cannot continue to update some of the model parameters. In contrast, the gradient of the ReLU activation function in the positive interval is always 1. Therefore, if the model parameters are not properly initialized, the sigmoid function may obtain a gradient of almost 0 in the positive interval, so that the model cannot be effectively trained.\n",
        "\n",
        "### Capacity Control and Preprocessing\n",
        "\n",
        "AlexNet controls the model complexity of the fully-connected layer\n",
        "by dropout (:numref:`sec_dropout`),\n",
        "while LeNet only uses weight decay.\n",
        "To augment the data even further, the training loop of AlexNet\n",
        "added a great deal of image augmentation,\n",
        "such as flipping, clipping, and color changes.\n",
        "This makes the model more robust and the larger sample size effectively reduces overfitting.\n",
        "We will discuss data augmentation in greater detail in :numref:`sec_image_augmentation`.\n"
      ],
      "metadata": {
        "id": "UcvYRzNouYx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mxnet import np, npx\n",
        "from mxnet.gluon import nn\n",
        "from d2l import mxnet as d2l\n",
        "\n",
        "npx.set_np()\n",
        "\n",
        "net = nn.Sequential()\n",
        "# Here, we use a larger 11 x 11 window to capture objects. At the same time,\n",
        "# we use a stride of 4 to greatly reduce the height and width of the output.\n",
        "# Here, the number of output channels is much larger than that in LeNet\n",
        "net.add(nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2),\n",
        "        # Make the convolution window smaller, set padding to 2 for consistent\n",
        "        # height and width across the input and output, and increase the\n",
        "        # number of output channels\n",
        "        nn.Conv2D(256, kernel_size=5, padding=2, activation='relu'),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2),\n",
        "        # Use three successive convolutional layers and a smaller convolution\n",
        "        # window. Except for the final convolutional layer, the number of\n",
        "        # output channels is further increased. Pooling layers are not used to\n",
        "        # reduce the height and width of input after the first two\n",
        "        # convolutional layers\n",
        "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
        "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
        "        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2),\n",
        "        # Here, the number of outputs of the fully-connected layer is several\n",
        "        # times larger than that in LeNet. Use the dropout layer to mitigate\n",
        "        # overfitting\n",
        "        nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
        "        nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
        "        # Output layer. Since we are using Fashion-MNIST, the number of\n",
        "        # classes is 10, instead of 1000 as in the paper\n",
        "        nn.Dense(10))"
      ],
      "metadata": {
        "id": "F6h4AXKiuaOI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We [**construct a single-channel data example**] with both height and width of 224 (**to observe the output shape of each layer**). It matches the AlexNet architecture in :numref:`fig_alexnet`.\n"
      ],
      "metadata": {
        "id": "K7HTDyV1ucXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.uniform(size=(1, 1, 224, 224))\n",
        "net.initialize()\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.name, 'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJlSxENudpc",
        "outputId": "6eb8566d-eb42-442a-ed1d-46c142a40e81"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv0 output shape:\t (1, 96, 54, 54)\n",
            "pool0 output shape:\t (1, 96, 26, 26)\n",
            "conv1 output shape:\t (1, 256, 26, 26)\n",
            "pool1 output shape:\t (1, 256, 12, 12)\n",
            "conv2 output shape:\t (1, 384, 12, 12)\n",
            "conv3 output shape:\t (1, 384, 12, 12)\n",
            "conv4 output shape:\t (1, 256, 12, 12)\n",
            "pool2 output shape:\t (1, 256, 5, 5)\n",
            "dense0 output shape:\t (1, 4096)\n",
            "dropout0 output shape:\t (1, 4096)\n",
            "dense1 output shape:\t (1, 4096)\n",
            "dropout1 output shape:\t (1, 4096)\n",
            "dense2 output shape:\t (1, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv1_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv1_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv2_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv2_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv3_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv3_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv4_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'conv4_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense1_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense1_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense2_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
            "/usr/local/lib/python3.7/dist-packages/mxnet/gluon/parameter.py:893: UserWarning: Parameter 'dense2_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
            "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Dataset\n",
        "\n",
        "Although AlexNet is trained on ImageNet in the paper, we use Fashion-MNIST here\n",
        "since training an ImageNet model to convergence could take hours or days\n",
        "even on a modern GPU.\n",
        "One of the problems with applying AlexNet directly on [**Fashion-MNIST**]\n",
        "is that its (**images have lower resolution**) ($28 \\times 28$ pixels)\n",
        "(**than ImageNet images.**)\n",
        "To make things work, (**we upsample them to $224 \\times 224$**)\n",
        "(generally not a smart practice,\n",
        "but we do it here to be faithful to the AlexNet architecture).\n",
        "We perform this resizing with the `resize` argument in the `d2l.load_data_fashion_mnist` function.\n"
      ],
      "metadata": {
        "id": "47S4nrypue1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
      ],
      "metadata": {
        "id": "j6w-nxZnugp0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now, we can [**start training AlexNet.**]\n",
        "Compared with LeNet in :numref:`sec_lenet`,\n",
        "the main change here is the use of a smaller learning rate\n",
        "and much slower training due to the deeper and wider network,\n",
        "the higher image resolution, and the more costly convolutions.\n"
      ],
      "metadata": {
        "id": "LXj_DWq2uiSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.01, 10\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "gVVLXpGzujqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "* AlexNet has a similar structure to that of LeNet, but uses more convolutional layers and a larger parameter space to fit the large-scale ImageNet dataset.\n",
        "* Today AlexNet has been surpassed by much more effective architectures but it is a key step from shallow to deep networks that are used nowadays.\n",
        "* Although it seems that there are only a few more lines in AlexNet's implementation than in LeNet, it took the academic community many years to embrace this conceptual change and take advantage of its excellent experimental results. This was also due to the lack of efficient computational tools.\n",
        "* Dropout, ReLU, and preprocessing were the other key steps in achieving excellent performance in computer vision tasks.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Try increasing the number of epochs. Compared with LeNet, how are the results different? Why?\n",
        "1. AlexNet may be too complex for the Fashion-MNIST dataset.\n",
        "    1. Try simplifying the model to make the training faster, while ensuring that the accuracy does not drop significantly.\n",
        "    1. Design a better model that works directly on $28 \\times 28$ images.\n",
        "1. Modify the batch size, and observe the changes in accuracy and GPU memory.\n",
        "1. Analyze computational performance of AlexNet.\n",
        "    1. What is the dominant part for the memory footprint of AlexNet?\n",
        "    1. What is the dominant part for computation in AlexNet?\n",
        "    1. How about memory bandwidth when computing the results?\n",
        "1. Apply dropout and ReLU to LeNet-5. Does it improve? How about preprocessing?\n"
      ],
      "metadata": {
        "id": "yJcKjxKXulSO"
      }
    }
  ]
}